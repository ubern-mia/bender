# Becoming one with the gradients

Welcome to Episode 05, and a new year/season of BENDER. This time we focus on gradients and interpretability, and go over in a humorous manner some of the considerations around understanding "how to open the black box" of modern AI. If this is of more interest to you, please also consider joining us for [BIAS '23](http://caim.unibe.ch/bias2023), a one-day online + in-person symposium hosted at the University of Bern on the 24th of March.

In this video of the [BENDER Series](https://github.com/ubern-mia/bender), we attempt to "open the black box", and understand how gradients can be helpful and also dangerous sometimes. We introduce new characters and topics, some helpful links for which are listed below:

--------------------

## Taxonomy of Interpretable AI

If you are confused about all the various terms used in this new but rapidly advancing field, consider reading [this](https://link.springer.com/article/10.1007/s10462-022-10256-8) well researched taxonomy, so we are all in agreement about what we are discussing.

## AIDA course on Interpretable AI

See [here](https://www.i-aida.org/course/introinterpretableai/) for an interesting introductory course on Interpretable AI by Dr. Mara Graziani and friends. 

## Interpretable AI video lectures by Prof. Hima Lakkaraju

See [here](https://www.youtube.com/playlist?list=PLoROMvodv4rPh6wa6PGcHH6vMG9sEIPxL) for a set of videos on YouTube by Prof. Hima Lakkaraju, from a recent event at Stanford. This extends well to the first ever "Interpretable AI course" taught at [Harvard](https://interpretable-ml-class.github.io) by Prof. Lakkaraju.

## Workshop on Interpretability of Machine Intelligence and Medical Image Computing - iMIMIC
[https://imimic-workshop.com](https://imimic-workshop.com) including talks and reference to articles published in the area of XAI for medical image computing.

## Other resources:
Check the thorough and awesome compilation of material from @jphall663 [awesome-interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability)
